{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac85eb-af22-4127-9804-32141801ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load poackages\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os, shutil, pathlib\n",
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88681e1b-73ef-421c-920b-b7da8f14988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load path of data\n",
    "\n",
    "original_dir = pathlib.Path(\"C:/Users/Antec/Desktop/Python_Kurs/Bootcamp/Final Project/Data/mixed\")\n",
    "new_base_dir = pathlib.Path(\"C:/Users/Antec/Desktop/Python_Kurs/Bootcamp/Final Project/Data/new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a88a8-a010-4372-9e62-5f124fbe63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make subsets mask/nomask\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"with_mask_\", \"without_mask_\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{category}{i+1}.jpg\"\n",
    "            for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname,\n",
    "                            dst=dir / fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9910f7d-c5c1-46b8-b6cb-580d8bc3eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_subset(\"train\", start_index=0, end_index=1000)\n",
    "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "make_subset(\"test\", start_index=1500, end_index=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8923887-29b4-411c-8436-bad3360163b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make badge and resize data\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "new_base_dir / \"train\",\n",
    "image_size=(180, 180),\n",
    "batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "new_base_dir / \"validation\",\n",
    "image_size=(180, 180),\n",
    "batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "new_base_dir / \"test\",\n",
    "image_size=(180, 180),\n",
    "batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df5fa3-1163-4584-8b2c-d05bba62e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create a classification model from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da36a7c1-bc0e-4a31-bca4-b85ee674cbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = keras.Input(shape=(180, 180, 3))\n",
    "# x = layers.Rescaling(1./255)(inputs)\n",
    "# x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "# x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "# x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "# x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "# x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d2af7-6506-4972-aaf8-49c7d59d13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=\"binary_crossentropy\",\n",
    "# optimizer=\"rmsprop\",\n",
    "# metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a3b4e-0ffa-4d22-89c5-a8651f2596fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [\n",
    "# keras.callbacks.ModelCheckpoint(\n",
    "# filepath=\"convnet_from_scratch.keras\",\n",
    "# save_best_only=True,\n",
    "# monitor=\"val_loss\")\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c92cd-efa5-4d48-b633-01f8d97ddafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "# train_dataset,\n",
    "# epochs=30,\n",
    "# validation_data=validation_dataset,\n",
    "# callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fcc6a0-65b0-461d-965d-e321161a24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# accuracy = history.history[\"accuracy\"]\n",
    "# val_accuracy = history.history[\"val_accuracy\"]\n",
    "# loss = history.history[\"loss\"]\n",
    "# val_loss = history.history[\"val_loss\"]\n",
    "# epochs = range(1, len(accuracy) + 1)\n",
    "# plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "# plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "# plt.title(\"Training and validation accuracy\")\n",
    "# plt.legend()\n",
    "# plt.figure()\n",
    "# plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "# plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "# plt.title(\"Training and validation loss\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78d806-7bf8-409a-bf69-e48020dc7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
    "# test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "# print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d081b0a6-7c5a-4073-8460-02d08c63acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import filters from vgg16\n",
    "\n",
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "weights=\"imagenet\",\n",
    "include_top=False,\n",
    "input_shape=(180, 180, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee90c6d2-5974-4d5b-b96a-5e49ba164956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pocess data through filters\n",
    "\n",
    "import numpy as np\n",
    "def get_features_and_labels(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for images, labels in dataset:\n",
    "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
    "        features = conv_base.predict(preprocessed_images)\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd35678-2b6f-4fb1-9018-b60c3c3aab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = get_features_and_labels(train_dataset)\n",
    "val_features, val_labels = get_features_and_labels(validation_dataset)\n",
    "test_features, test_labels = get_features_and_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd544cfc-6cbb-4a39-a8e3-e486d55ff687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up model from dropout and dense layers\n",
    "\n",
    "inputs = keras.Input(shape=(5, 5, 512))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf4f14-7bce-42b8-ba5d-f54efaa6a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and save the dense layers\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "optimizer=\"rmsprop\",\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "keras.callbacks.ModelCheckpoint(\n",
    "filepath=\"feature_extraction.keras\",\n",
    "save_best_only=True,\n",
    "monitor=\"val_loss\")\n",
    "]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "train_features, train_labels,\n",
    "epochs=20,\n",
    "validation_data=(val_features,val_labels),\n",
    "callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79e1810-7c92-4ec2-837a-e56dc8e8cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on test data\n",
    "\n",
    "test_model = keras.models.load_model(\"feature_extraction.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_features, test_labels)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9507e8-880d-41e9-992d-bc35540cde13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize training and validation loss and accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
